# Lumi LLM - API de Chat con OpenAI y Perplexity

Una API REST construida con FastAPI que proporciona endpoints para interactuar con modelos de IA de OpenAI, especializada en consultas de crianza.

## ğŸš€ CaracterÃ­sticas

- **OpenAI Integration**: Endpoint `/api/chat` para consultas con GPT-4o
- **CORS habilitado** para desarrollo
- **Dockerizado** para fÃ¡cil despliegue
- **Variables de entorno** configurables

## ğŸ“‹ Requisitos Previos

- Docker y Docker Compose instalados
- Cuenta de OpenAI con API key

## ğŸ› ï¸ ConfiguraciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/IamNewInThis/lumi_LLM.git
cd lumi_LLM
```

### 2. Configurar variables de entorno
Crea un archivo `.env` en la raÃ­z del proyecto:

```env
# Puerto del servidor (por defecto: 8000)
PORT=8000

# OpenAI Configuration
OPENAI_API_KEY=tu_openai_api_key_aqui
OPENAI_MODEL=gpt-4o

SUPABASE_URL=supabase_url
SUPABASE_SERVICE_ROLE_KEY=supabase_service_role_key
```

**âš ï¸ Importante**: Reemplaza `tu_openai_api_key_aqui` con tu clave real de OpenAI.

## ğŸ³ Uso con Docker

### OpciÃ³n 1: Docker Compose (Recomendado)

```bash
# Construir y ejecutar
docker-compose up --build

# Ejecutar en segundo plano
docker-compose up --build -d

# Ver logs
docker-compose logs -f

# Detener
docker-compose down
```

### OpciÃ³n 2: Docker directamente

```bash
# Construir la imagen
sudo docker build -t lumi-llm .

# Ejecutar el contenedor
sudo docker run -t lumi-llm
docker compose up

# Reiniciar el contenedor
sudo docker restart -t lumi-llm 

# Detener el contenedor
sudo docker stop lumi-api
docker rm lumi-api

# Ver contenedores en ejecuciÃ³n
sudo docker ps
```

## ğŸŒ Uso de la API

Una vez que el contenedor estÃ© ejecutÃ¡ndose, la API estarÃ¡ disponible en `http://localhost:8000`.

### DocumentaciÃ³n automÃ¡tica
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Endpoints disponibles

#### 1. Chat con OpenAI
```bash
POST /api/chat
Content-Type: application/json

{
  "message": "Â¿CÃ³mo puedo ayudar a mi hijo de 3 aÃ±os a dormir mejor?",
  "profile": {
    "edad_hijo": "3 aÃ±os",
    "problema": "dificultad para dormir"
  }
}
```

### Ejemplo con cURL

```bash
# OpenAI
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Mi hijo tiene rabietas constantes, Â¿quÃ© puedo hacer?",
    "profile": {"edad": "4 aÃ±os"}
  }'

# Perplexity
curl -X POST "http://localhost:8000/api/chat/pplx" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Â¿Es normal que un bebÃ© de 6 meses se despierte cada 2 horas?",
    "profile": {"edad": "6 meses"}
  }'
```

## ğŸ”§ Desarrollo

### Ejecutar localmente (sin Docker)

```bash
# Instalar dependencias
pip install -r requirements.txt

# Ejecutar servidor
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

### Estructura del proyecto

```
lumi_LLM/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ chat.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â””â”€â”€ .env  # (crear)
```

## ğŸš¨ SoluciÃ³n de Problemas

### Error: "Invalid value for '--port': '${PORT}' is not a valid integer"
- **SoluciÃ³n**: AsegÃºrate de que el archivo `.env` existe y contiene `PORT=8000`

### Error: "Falta OPENAI_API_KEY en variables de entorno"
- **SoluciÃ³n**: Agrega tu clave de OpenAI al archivo `.env`

### El contenedor no inicia
- **SoluciÃ³n**: Verifica que el puerto 8000 no estÃ© siendo usado por otra aplicaciÃ³n
- **Alternativa**: Cambia el puerto en `.env` y en `docker-compose.yml`

### Error de permisos en Docker
- **SoluciÃ³n**: En Linux/Mac, ejecuta con `sudo` si es necesario

## ğŸ“ Notas de ProducciÃ³n

- Cambia `allow_origins=["*"]` en `main.py` por tu dominio especÃ­fico
- Usa un proxy reverso (nginx) para SSL/TLS
- Configura variables de entorno de forma segura
- Considera usar Docker secrets para claves sensibles

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.
